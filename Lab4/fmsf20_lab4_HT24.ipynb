{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datorlaboration 4\n",
    "\n",
    "## Syfte:\n",
    "Syftet med dagens laborationen är att du skall bli mer förtrogen med :\n",
    "* Enkel linjär regression.\n",
    "* Multipel linjär regression.\n",
    "\n",
    "\n",
    "## Förberedelseuppgifter\n",
    "1. Repetera grafisk fördelningsanpassning (tex. normalfördelningsdiagram eller QQ-plot), läs genom hela regressionsdelen i statistikkompendiet (avsnitt 4-6) och hela denna laborationshandledning.\n",
    "2. Ange modellen för enkel linjär regression och normalfördelade fel.\n",
    "    1. **Mozquizto:** Hur skattar vi $\\alpha, \\beta$ och $\\sigma^2$?\n",
    "    2. Vilken fördelning får $\\alpha^*$ och $\\beta^*$?\n",
    "    3. Hur gör vi konfidensintervall för $\\alpha$ och $\\beta$?\n",
    "    4. **Mozquizto:** Hur kan vi testa huruvida linjens lutning är 0?\n",
    "3. **Mozquizto:** \n",
    "    1. Hur ser ett konfidensintervall för $\\mu_0 = \\alpha + \\beta x_0$ ut?\n",
    "    2. Vad är ett prediktionsintervall och hur räknas det ut?\n",
    "    3. Vad är ett kalibreringsintervall och hur kan det konstrueras?\n",
    "4. Residualanalys är ett centralt moment i all regressionsanalys. Hur bör residualerna se ut vid en korrekt regressionsanalys? Ange några tekniker för att kontrollera detta.\n",
    "5. Ange modellen för multipel linjär regression på matrisform.\n",
    "6. **Mozquizto:** Hur ser normalekvationerna ut och hur löser vi dessa? Vad blir kovariansmatrisen för för $\\boldsymbol{\\beta}^*$?\n",
    "7. Lös uppgift ST35.\n",
    "\n",
    "# Importera moduler och ladda upp filer till Colab\n",
    "Kör koden nedan för att hämta de väsentliga modulerna vi kommer att använda i laborationen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utöver modulerna ovan använder laborationen ett par funktioner och datamaterial.\n",
    "1. Ladda ner filerna från kurshemsidan\n",
    "2. Klicka på mappen *Filer* till vänster i *google colab* menyn\n",
    "3. Ladda upp filerna genom att klicka på *Ladda upp till sessionens lagringsutrymme* (eller drag-n-drop filen)\n",
    "\n",
    "### Google Colabs\n",
    "\n",
    "se till att rätt sökväg till datan används."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#Addera content till sökvägen för python\n",
    "sys.path.append('/content')  #Här kan du behöva uppdater sökvägen.\n",
    "#importera funktionerna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Egen dator\n",
    "\n",
    "Se till att rätt sökväg till datan används."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enkel linjär regression\n",
    "Vid enkel linjär regression söker anpassas en rät linje till datamaterialet, dvs modellen är \n",
    "\n",
    "\\begin{align}\n",
    "Y_i=\\alpha+\\beta x_i+ \\epsilon_i,\\ i=1,...,n, \\nonumber\n",
    "\\end{align}\n",
    "\n",
    "där $\\epsilon_i$ är oberoende likafördelade störningar med väntevärdet $\\theta$ och variansen $\\sigma^2$.\n",
    "Vi kommer i den följande framställningen att arbeta med matrisformuleringen av modellen,\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{Y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} \\nonumber\n",
    "\\end{align}\n",
    "\n",
    "där de ingående matriserna har följande form:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{Y} = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{pmatrix}, \\quad\n",
    "\\mathbf{X} = \\begin{pmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{pmatrix}, \\quad\n",
    "\\boldsymbol{\\beta} = \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix}, \\quad\n",
    "\\text{och} \\quad\n",
    "\\boldsymbol{\\epsilon} = \\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix} \\nonumber\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Uppgift ST35\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi vill börja med att själva implementera en skattare av parametrarna i regressionsmodellen. Vi definierar våra beroende och oberoende variabler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([1.5, 2.3, 1.7, 2.0, 2.5, 1.9, 2.2, 2.4 ])\n",
    "x = np.arange(8)+1\n",
    "n = np.shape(x)\n",
    "X = np.column_stack( (np.ones(n), ? ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nästa steg är att skatta parametrarna $\\alpha$ och $\\beta$ samt standardavvikelsen $\\sigma$. Genomför beräkningarna som matrisoperationer (ex. `A @ B`) enligt regressionsmaterialet och visualisera sedan resultatet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invXTX = np.linalg.inv(X.T @ X)\n",
    "ab = invXTX @ (? @ ?)\n",
    "\n",
    "e = y-(X @ ab) # skattade residualer\n",
    "f = n[0] - 2 # antal frihetsgrader - antal obs minus antal skattade parametrar. \n",
    "s = np.sqrt( e.T @ e /f) # skattad standardavvikelse\n",
    "\n",
    "print(ab) # skriv ut parametervärdena för alpha,beta\n",
    "\n",
    "plt.clf()\n",
    "sns.scatterplot(x=?,y=?,markers='x') # observationer (x,y)\n",
    "sns.lineplot(x=x,y=(X @ ab),color='red') # den skattade linjen y = X * beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi vill sedan skapa konfidensintervall för $\\alpha$ och $\\beta$. För att göra det krävs att vi beräknar skattningarnas respektive medelfel, $d(\\cdot)$. 95 % konfidensintervall kan sedan konstrueras: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = s**2*? # skattad kovariansmatris för parameterskattningarna\n",
    "d = np.sqrt(np.diag(C)) # medelfelen som vektor \n",
    "p = 0.05 # signifikansnivå\n",
    "tinv = stats.t.ppf(1-p/2,f) #t-kvantil\n",
    "Ia = ab[?] + np.array([-1,1])*tinv*d[?]\n",
    "Ib = ab[?] + np.array([-1,1])*tinv*d[?]\n",
    "\n",
    "R2 = 1 - (e.T @ e)/( (y.T @ y) - np.sum(y)**2/n[0] ) # förklaringsgrad\n",
    "print(R2)\n",
    "\n",
    "print(Ia)\n",
    "print(Ib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uppgift:** Stämmer parameterskattningarna med beräkningarna i förberedelseuppgift 7?\n",
    "\n",
    "Pythonpaketet `statsmodels` innehåller inbyggda funktioner för allehanda linjära modeller, däribland för linjär regression. Vi ska nu använda detta för att skatta parametrarna och konstruera konfidensintervall för dessa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(x) # lägger till en kolumnvektor med ettor först.\n",
    "model = sm.OLS(y,X).fit() # anpassar enkel/multipel linjär regressionsmodell\n",
    "print(model.summary()) # visar den sammanfattande statistiken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uppgift:** Identifiera parameterskattningen och deras konfidensintervall och jämför med tidigare beräkningar.\n",
    "\n",
    "Vi ska också analysera residualerna visuellt och kontrollera att dessa uppfyller modellantaganden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = model.resid\n",
    "yhat = model.fittedvalues\n",
    "\n",
    "sns.scatterplot(x=yhat,y=y)\n",
    "plt.xlabel(\"y skattad\")\n",
    "plt.ylabel(\"y data\")\n",
    "plt.axline((2,2),slope=1,color=\"red\")\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(x=?,y=?) # plotta residualer mot x\n",
    "plt.axline((0,0),slope=0,color=\"red\")\n",
    "fig,ax = plt.subplots(1,1)\n",
    "fig = stats.probplot(?,dist=\"norm\",plot=ax) # lämplig fördelningsanpassning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uppgift:** Jämför de tre plottarna - vilka verifierar våra modellantaganden?\n",
    "\n",
    "## Polynomregression\n",
    "\n",
    "Datamaterialet som du skall arbeta med i detta avsnitt är koldioxidhalter uppmätta vid Mauna Loa (www.co2.earth/monthly~co2) varje månad under 32 år, totalt finns $32 \\cdot 12 = 384$ mätvärden. Materialet finns i filen `co2.csv`, och vi börjar med att ladda in den med `pandas`. Därefter medelvärdesbildar vi för varje år för att ta hand om årsvariationen, vilken annars är komplicerad att modellera. Detta görs genom att göra om `co2` till en (32,12) matris och sedan medelvärdesbilda över den andra dimensionen. Vi plottar sedan dessa två dataserier i samma plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2 = pd.read_csv(\"co2.csv\") \n",
    "\n",
    "y = np.mean(np.reshape(np.array(co2[\"co2\"]),(-1,12)),axis=?)\n",
    "x = np.arange(np.size(y),dtype=float)+1\n",
    "\n",
    "sns.scatterplot(x=np.linspace(0,32,np.size(co2[\"co2\"])),y=co2[\"co2\"])\n",
    "sns.scatterplot(x=x,y=y)\n",
    "plt.xlabel(\"tid (år)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uppgift:** Vad kan vi säga om den medelvärdesbildade dataserien? Är periodiciteten kvar?\n",
    "\n",
    "Vi ska nu göra polynomregression för den medelvärdesbildade datan `y`, dvs använda modellen\n",
    "\n",
    "\\begin{align}\n",
    "Y_i = \\beta_0 + \\beta_1 \\, x_i + \\beta_2 \\, x_i^2 + \\dots + \\beta_k \\, x_i^k + \\epsilon_i, \\ i=1,\\dots,n\n",
    "\\nonumber\n",
    "\\end{align}\n",
    "där $\\epsilon_i$ är oberoende och likafördelade avvikelser $N(0,\\sigma)$. På matrisform kan vi således använda modellen \n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{Y} =  \n",
    "\\mathbf{X} \\, \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon},\n",
    "\\quad \n",
    "\\mathbf{X} = \n",
    "\\begin{bmatrix}\n",
    "\\mathbf{1}_n & \\mathbf{x} & \\mathbf{x}^2 & \\cdots & \\mathbf{x}^k\n",
    "\\end{bmatrix}\n",
    "\\nonumber\n",
    "\\end{align}\n",
    "\n",
    "där $\\mathbf{x}^\\ell$ anger x-vektorn elementvis upphöjd till $\\ell$. Vi börjar med $k=1$ och ökar därefter $k \\leftarrow k +1 $. För varje modellordning vill vi avgöra om\n",
    "\n",
    "1. Verkar modellen passa till datan (plotta $\\mathbf{y}$ mot skattningen $\\mathbf{X}\\, \\boldsymbol{\\beta}^*_{obs}$)\n",
    "2. Är residualerna $\\mathbf{e} = \\mathbf{y} - \\mathbf{X}\\, \\boldsymbol{\\beta}^*_{obs}$ oberoende och normalfördelade?\n",
    "3. Är parametrarna i $\\boldsymbol{\\beta}$ signifikant skilda från noll? Annars är modellen för stor och en utan den ej signifikanta parametern bör användas.\n",
    "\n",
    "Testa olika ordningar $k$ och försök avgöra vilken modell som är bäst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bygg regressionsmatrisen med k polynomordningar:\n",
    "X = x # 1:a ordningen \n",
    "X = np.column_stack((X,np.power(x,2))) # 2:a ordningen  \n",
    "#X = np.column_stack((X,?)) # 3:e ordningen\n",
    "#X = np.column_stack((X,?)) # 4:e ordningen\n",
    "# ... osv                 \n",
    "X = sm.add_constant(X) # lägger till en kolumnvektor med ettor först.\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "model = sm.OLS(y,?).fit() # anpassar enkel/multipel linjär regressionsmodell\n",
    "print(model.summary()) # visar den sammanfattande statistiken\n",
    "\n",
    "sns.scatterplot(y=y,x=x).set(title=\"Modelfit\")\n",
    "sns.lineplot(y=model.fittedvalues,x=x)\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(x=x,y=model.resid).set(title=\"Residualplot\")\n",
    "plt.axline((0,0),slope=0)\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "fig = stats.probplot(model.resid,dist=\"norm\",plot=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mozquizto:** Vad verkar vara ett lämpligt gradtal på polynomet för `co2`-datan?\n",
    "\n",
    "**Mozquizto:** Vad är $\\beta$-koefficienterna för detta polynom?\n",
    "\n",
    "## Multipel regression\n",
    "\n",
    "Vi ska fortsätta med att skatta regressionsmodeller innehållandes fler än en förklarande variabler. Vi kan välja vilka vi vill inkludera i modellen på olika sätt. Ovan byggde vi regressionmatrisen manuellt, men det finns även inbyggda funktioner för detta.\n",
    "\n",
    "### Cementdata\n",
    "\n",
    "I ett klassiskt experiment mättes i $n=13$ försök värmeutvecklingen i stelnande cement som funktion av viktprocenten av några ingående ämnen. I filen `cement.csv` finns följande variabler:\n",
    "\n",
    "* `cem1`: viktprocent av $3CaO \\cdot Al_2 O_3$\n",
    "* `cem2`: viktprocent av $3CaO \\cdot SiO_2$\n",
    "* `cem3`: viktprocent av $4CaO \\cdot Al_2 O_3 \\cdot F3_2 O_3$\n",
    "* `cem4`: viktprocent av $2CaO \\cdot SiO_2$\n",
    "* `varme`: utvecklad värme i kalorier per gram cement\n",
    "\n",
    "Vissa av de fyra cementvariablerna samvarierar kraftigt med varandra vilket påverkar regressionsanalysen. Plotta responsvariabeln `varme` mot de fyra cementvariablerna samt beräkna korrelationsmatrisen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cement = pd.read_csv(\"cement.csv\",names=[\"cem1\",\"cem2\",\"cem3\",\"cem4\",\"varme\"]) \n",
    "sns.pairplot(cement,y_vars=\"varme\")\n",
    "print(cement.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mozquizto:** Vilka variabler verkar samvariera?\n",
    "\n",
    "Vi börjar likväl med att skatta en fullregressionsmodell för samtliga fyra förklarande variabler, samt ett intercept. Genom att använda `statsmodels` kan vi enkelt lägga till och ta bort förklarande variabler. Observera att interceptet alltid inkluderas med denna metodik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula='varme ~ cem1 + cem2 + cem3 + cem4',data=cement).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mozquizto:** Vilka regressionskoefficienter är signifikant skilda från noll på nivån 0.05?\n",
    "\n",
    "Förmodligen är du inte alls nöjd med din skattade modell. Ett sätt att hitta den bästa modellen innehållande mellan en och fyra förklarande variabler är att testa samtliga $4!$ kombinationer. Det kan dock vara onödigt arbetsamt - det finns många andra sätt. Ett är att börja med en minimal modell (enkel linjär regression) och sedan lägga till nya förklarande variabler en efter en. Börja t. ex. med den variabel som har högst absolut korrelation med `varme`. Arbeta dig successivt fram till den bästa modellen och glöm inte residualanalysen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula='varme ~ ?',data=cement).fit()\n",
    "cement[\"yhat\"] = model.fittedvalues\n",
    "cement[\"resid\"] = model.resid\n",
    "\n",
    "print(model.summary())\n",
    "print(cement.corr())\n",
    "\n",
    "sns.scatterplot(cement, x=\"yhat\",y=\"varme\")\n",
    "plt.xlabel(\"y skattad\")\n",
    "plt.ylabel(\"y data\")\n",
    "plt.axline((100,100),slope=1,color=\"red\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "sns.pairplot(cement,y_vars=\"?\") # residualplot\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "fig = stats.probplot(cement[\"?\"],dist=\"norm\",plot=ax) # normplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mozquizto:** Vilken modell kom du fram till?\n",
    "\n",
    "**Mozquizto:** Vad blir skattningarna av $\\boldsymbol{\\beta}$ för din valda modell?\n",
    "\n",
    "\n",
    "## Kalibrering av flödesmätare\n",
    "\n",
    "### Bakgrund\n",
    "\n",
    "Kalibrering av flödesmätare görs i en speciell kalibreringsrigg där mätningarna från en referensmätare eller referensmetod kan jämföras med mätaren som håller på att kalibreras. Det ger talpar med kalibreringsriggens värden och flödesmätarens värden och dessa används för att ta fram en s.k. kalibreringskurva. Denna kurva avläses  \n",
    "\n",
    "### Metod\n",
    "\n",
    "Vi har tillgång till data från en kalibrering av en ultraljudflödesmätare. Datamaterialet kommer från institutionen för värme- och kraftteknik och omfattar $n=71$ mätningar vilka finns i filen `flow2.csv`. Den första kolumnen innehåller flödesmätningen från kalibreringsriggen (förklarande variabeln $\\mathbf{x}$) och den andra innehåller flödesmätningen från den testade flödesmätaren (responsvariabeln $\\mathbf{y}$), i enheten m/s.\n",
    "\n",
    "Vi antar att vi kan skatta den testade mätarens flöden som funktion av referensmätningen med en enkel linjär regressionmodell. Det är rimligt att felen i referensmätningarna är försumbara (varför är detta viktigt?) i jämförelse med de uppmätta, vilka antas vara oberoende och normalfördelade med väntevärden 0 och varianser $\\sigma^2$.\n",
    "\n",
    "Vi börjar med att studera en liten delmängd av datamaterialet, $n=10$ mätningar, vilka finns i `flow1.csv`.\n",
    "\n",
    "Vi vill nu beräkna:\n",
    "\n",
    "* Den testade flödesmätarens förväntade värde då flödet enligt kalibreringsriggen är $x=0.40$ m/s, samt ett konfidensintervall för detta väntevärde.\n",
    "* Ett prediktionsintervall för en flödesmätarens faktiska värde då flödet ställts in $x=0.40$ m/s. \n",
    "* När flödesmätaren ska användas in situ skall kalibreringskurvan läsas inverterat. Man är alltså intresserad av vad det faktiska flödet är (referensvärdet $x$) då flödesmätaren visar $y=0.48$. Specifikt skall ett 95 % kalibreringsintervall för detta $x(y=0.48)$ beräknas.\n",
    "\n",
    "Alla dessa kan utläsas ur figuren med linjen, konfidensintervall för linjen, samt prediktionsintervall. Kalibreringsintervallet kan utläsas utifrån prediktionsintervallet för den aktuella $x(y=y_o)$ (se regressionskompendiet). \n",
    "\n",
    "Glöm inte att vi också måste validera modellen, dvs bekräfta att regressionsmodellen beskriver sambandet bra och att residualerna följer gjorda antagande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = pd.read_csv(\"flow1.csv\",names=[\"ref\",\"obs\"])\n",
    "\n",
    "model = smf.ols(data=flow,formula=\"obs ~ ref\").fit()\n",
    "flow[\"yhat\"] = model.fittedvalues\n",
    "flow[\"resid\"] = model.resid\n",
    "print(model.summary())\n",
    "\n",
    "flow_interp = pd.DataFrame({'ref':  np.linspace(0.38,0.48,100)}) # ange område att titta kring\n",
    "\n",
    "pred = model.get_prediction(flow_interp).summary_frame(alpha=0.05)\n",
    "flow_interp[\"mean\"] = pred[\"mean\"]\n",
    "flow_interp[\"ci_lower\"] = pred[\"mean_ci_lower\"]\n",
    "flow_interp[\"ci_upper\"] = pred[\"mean_ci_upper\"]\n",
    "flow_interp[\"pi_lower\"] = pred[\"obs_ci_lower\"]\n",
    "flow_interp[\"pi_upper\"] = pred[\"obs_ci_upper\"]\n",
    "\n",
    "sns.scatterplot(flow,x=\"ref\",y=\"obs\")\n",
    "sns.lineplot(flow_interp,x=\"ref\",y=\"mean\")\n",
    "sns.lineplot(flow_interp,x=\"ref\",y=\"ci_lower\",color=\"red\",linestyle=\"--\")\n",
    "sns.lineplot(flow_interp,x=\"ref\",y=\"ci_upper\",color=\"red\",linestyle=\"--\")\n",
    "sns.lineplot(flow_interp,x=\"ref\",y=\"pi_lower\",color=\"green\",linestyle=\"--\")\n",
    "sns.lineplot(flow_interp,x=\"ref\",y=\"pi_upper\",color=\"green\",linestyle=\"--\")\n",
    "plt.xlim([0.435,0.46])\n",
    "plt.ylim([0.45,.55])\n",
    "\n",
    "plt.figure()\n",
    "sns.pairplot(flow,y_vars=\"?\",x_vars={\"ref\",\"resid\"})\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "fig = stats.probplot(flow[\"?\"],dist=\"norm\",plot=ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mozquizto:** Vad blev konfidensintervallet, prediktionsintervallet och kalibreringsintervallet beräknat ovan?\n",
    "\n",
    "Gör nu om beräkningarna för det större datamaterialet `flow2.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = pd.read_csv(\"flow1.csv\",names=[\"ref\",\"obs\"])\n",
    "\n",
    "# ... Fyll i lämplig kod här."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mozquizto:** Vad blev konfidensintervallet, prediktionsintervallet och kalibreringsintervallet beräknat på det större datamaterialet?\n",
    "\n",
    "Jämför bredden på intervallen för det mindre och det större datamaterialet. Skiljer de sig åt väsentligt eller inte och varför?\n",
    "\n",
    "Vi kan också beräkna intervallen exakt, istället för att utläsa ur figuren. För linjens värde $\\mu(x_0)$, dess konfidensintervall $I_{\\mu(x_0)}$ och prediktionsintervallet $I_{y(x_0)}$ beräknas detta med `.get_prediction(flow0).summary_frame(alpha=0.05)`, där `flow0` är en ny dataframe innehållandes värdet $x_0$. För kalibreringsintervallet räknar vi efter formeln i regressionskompendiet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# linjen=förväntat värde, konfidensintervall, prediktionsintervall:\n",
    "x0 = ?\n",
    "flow0 = pd.DataFrame({'ref': [x0]})\n",
    "pred0 = model.get_prediction(flow0).summary_frame(alpha=0.05)\n",
    "print(pred0)\n",
    "\n",
    "# kalibreringsintervall:\n",
    "y0 = ?\n",
    "Sxx = np.sum( np.power(flow[\"ref\"] - np.mean(flow[\"ref\"]),2))\n",
    "xcal0 = (y0 - model.params[0])/model.params[1]\n",
    "dxcal0 = model.scale**0.5 / np.abs(model.params[1])*np.sqrt(1 + 1/flow.shape[0] + (y0-np.mean(flow[\"obs\"]))**2 / model.params[1]**2 / Sxx)\n",
    "tinv = stats.t.ppf(1-0.05/2,model.df_resid) #t-kvantil\n",
    "Ixcal0 = xcal0 + np.array([-1,1])*tinv*dxcal0\n",
    "\n",
    "print(Ixcal0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mozquizto:** Vad blir de exakta beräkningarna av förväntat värde, konfidensintervall för detta, prediktionsintervall samt kalibreringsintervall?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
